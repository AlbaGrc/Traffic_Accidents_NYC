{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PREPROCESSING\n",
    "\n",
    "Initially, the data is preprocessed to create a clean and complete dataset for analysis. This involves standardizing formats, completing missing records and addressing any inconsistencies to ensure the reliability of subsequent analyses.\n",
    "\n",
    "For this make sure to have a folder named **data** within this repository where the following csv files should appear:\n",
    "- accidents_original.csv\n",
    "- weather2018.csv\n",
    "- borough_area.csv\n",
    "- zip_code_area.csv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['CRASH DATE', 'CRASH TIME', 'BOROUGH', 'ZIP CODE', 'LATITUDE',\n",
      "       'LONGITUDE', 'LOCATION', 'ON STREET NAME', 'CROSS STREET NAME',\n",
      "       'OFF STREET NAME', 'NUMBER OF PERSONS INJURED',\n",
      "       'NUMBER OF PERSONS KILLED', 'NUMBER OF PEDESTRIANS INJURED',\n",
      "       'NUMBER OF PEDESTRIANS KILLED', 'NUMBER OF CYCLIST INJURED',\n",
      "       'NUMBER OF CYCLIST KILLED', 'NUMBER OF MOTORIST INJURED',\n",
      "       'NUMBER OF MOTORIST KILLED', 'CONTRIBUTING FACTOR VEHICLE 1',\n",
      "       'CONTRIBUTING FACTOR VEHICLE 2', 'CONTRIBUTING FACTOR VEHICLE 3',\n",
      "       'CONTRIBUTING FACTOR VEHICLE 4', 'CONTRIBUTING FACTOR VEHICLE 5',\n",
      "       'COLLISION_ID', 'VEHICLE TYPE CODE 1', 'VEHICLE TYPE CODE 2',\n",
      "       'VEHICLE TYPE CODE 3', 'VEHICLE TYPE CODE 4', 'VEHICLE TYPE CODE 5'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Read CSV file\n",
    "df = pd.read_csv('data/accidents_original.csv')\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we are going to substract columns which do not provide information relevant for our analysis, which at first mainly include all contributing factors except for car 1, other vehicles type but 1 and redundant location information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['NUMBER OF PERSONS INJURED', 'NUMBER OF PERSONS KILLED', 'CONTRIBUTING FACTOR VEHICLE 2', \n",
    "                 'CONTRIBUTING FACTOR VEHICLE 3', 'CONTRIBUTING FACTOR VEHICLE 4', 'CONTRIBUTING FACTOR VEHICLE 5', \n",
    "                 'VEHICLE TYPE CODE 2', 'VEHICLE TYPE CODE 3', 'VEHICLE TYPE CODE 4', 'VEHICLE TYPE CODE 5', \n",
    "                 'CROSS STREET NAME', 'OFF STREET NAME', 'LOCATION', 'COLLISION_ID', 'ON STREET NAME'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'VEHICLE TYPE CODE 1': 'VEHICLE TYPE'}, inplace=True)\n",
    "df.rename(columns={'CONTRIBUTING FACTOR VEHICLE 1': 'CONTRIBUTING FACTOR'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, since some of the cars have been incorrectly typen and there are over 217 classes, we are going to do clusters for car types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VEHICLE TYPE\n",
      "Sedan                                  36536\n",
      "Station Wagon/Sport Utility Vehicle    28200\n",
      "Taxi                                    3818\n",
      "Pick-up Truck                           2479\n",
      "Box Truck                               1678\n",
      "                                       ...  \n",
      "HEAVY                                      1\n",
      "R/V                                        1\n",
      "Work                                       1\n",
      "CASE                                       1\n",
      "mail                                       1\n",
      "Name: count, Length: 217, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['VEHICLE TYPE'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "services = ['abulance', 'almbulance','AMB', 'AMBU', 'AMBUL', 'AMBULACE','AMBULANCE','AMBULENCE', 'fdny ems', 'FDNY AMBUL', 'Leased amb',\n",
    "             'ambulance', 'FDNY ENGIN','NYC AMBULA', 'fdny ambulance', 'GEN AMBUL', 'FDNY Engin', 'Sanit', 'NYFD', 'Ambulance','FDNY #226', \n",
    "             'GEN  AMBUL', 'J1', 'E REVEL SC', 'NYPD', 'FDNY Ambul', 'ambu', 'Ambul', 'ambul', 'Fire Truck', 'Fire Engin', 'Fire truck', \n",
    "             'Fire', 'FDNY FIRE', 'FIRE TRUCK', 'FDNY TRUCK', 'FIRTRUCK', 'FDNY fire', 'fire truck', 'FIRE','FIRETRUCK','FIRE ENGIN',\n",
    "             'FD tr', 'fd tr', 'FD TR', 'fdny', 'FDNY', 'FIRET', 'firet', 'NYC', 'fire', 'government', 'GOVER', 'NYC FD']\n",
    "\n",
    "car = ['Sedan', 'PK', 'Convertible', 'Station Wagon/Sport Utility Vehicle', 'MOTOR SKAT', 'PICK UP', 'Can',\n",
    "       '4 dr sedan', 'UNK', 'Pick up tr', 'SUV', 'FLAT', '3-Door', 'SMART CAR', 'Street Cle', '2 dr sedan', \n",
    "       'CHEVY EXPR', 'suburban', 'Pick up Tr', 'F150XL PIC', 'Wh Ford co','MINI', 'Motorized Home', 'RV', 'R/V', \n",
    "       'Box t', 'Pickup with mounted Camper', 'Subn', 'UHAUL', 'SLINGSHOT', 'UT', 'cross', \n",
    "       'Elect', 'Hopper', 'OMR', 'RGS', 'CAMP', 'PICKU', 'ELECT', '2- to']\n",
    "\n",
    "van = ['Van', 'van', 'ford van', 'Van Camper', 'WORK VAN', 'VAN T', 'Work Van', 'Cargo Van']\n",
    "\n",
    "truck = ['Tractor Truck Diesel', 'Flat Bed', 'Box Truck', 'Pick-up Truck', 'Dump', 'Concrete Mixer', 'Tanker', \n",
    "         'Tractor Truck Gasoline', 'FDNY LADDE', 'Tow Truck / Wrecker', 'Chassis Cab', \n",
    "         'Bulk Agriculture', 'FLATBED FR', 'Open Body', 'Flat Rack', 'Armored Truck', 'truck', 'TRAILER', \n",
    "         'Lift Boom','BOX TRUCK', 'Cement Tru', 'USPS/GOVT', 'TRUCK VAN', 'UTILITY', 'utility', 'POWER SHOV', \n",
    "         'DELIVERY T', 'SWT', 'Trac', 'USPS', 'Beverage Truck', 'Refrigerated Van', 'PSD', 'TRAC', 'Tow Truck', 'COURIER',\n",
    "         'Courier', 'message si', 'box', 'F550','DELV', 'box truck', 'commercial', 'Tractor tr', 'TRUCK', \n",
    "         'Stake or Rack', 'COMMERCIAL', 'dilevery t', 'FREIGHT FL', 'MOVING VAN',  'UPS TRUCK', 'dump truck', 'Freight', \n",
    "         'USPS VAN', 'TRUCK FLAT', 'BOBCAT FOR', 'Tractor Tr', 'DELIVERY V', 'DOT EQUIPM', 'Livestock Rack', 'DUMP', '18 WHEELER', \n",
    "         'MAIL TRUCK', 'FOOD TRUCK', 'Bucket Tru', 'FLATBED', 'POSTO', 'FREIG', 'DELIV', 'trail', \n",
    "         'TRAIL', 'UTILITY VE', 'HEAVY', 'UPS T', 'BACKH', 'Tractor', 'Light Trai', 'Fork lift',  'FORK LIFT', \n",
    "         'Dump', 'Utility', 'Pumper', 'Front-Load', 'DRILL RIG', 'MECHANICAL', 'mail', 'Garba', 'TRACT', \n",
    "         'Garbage or Refuse', 'GARBAGE TR', 'Trailer', 'trailer', 'UTIL', 'Delv',\n",
    "         'ROAD SWEEP', 'LIGHT TRAI', 'USPS TRUCK', 'USPS TRUCK', 'usps', 'Semi', 'CEMEN', 'Backh', 'deliv', 'tow', 'dump', 'Elect', 'utili',\n",
    "         'Util', 'ACCES', 'BOBCA' ,'TANK' ,'TRACK', 'utili', 'FOOD', 'Spc', 'BED T', 'comme', 'PAS', 'SWEEP', 'BOX T', \n",
    "         'CASE', 'Work', 'LIBER', 'COMB', 'DUMPS', 'Utili', 'cross', 'gator', 'CAT', 'GARBA', \n",
    "         'semi',  'UTILI', 'R/V C', 'sgws', 'Cat 9', 'MACK', 'SPC', 'Enclosed Body - Removable Enclosure', 'delv', 'MAIL', \n",
    "         'box t', 'garba', 'CONCR', 'Pallet', 'FED E', 'COMME', 'TRLR', 'LOADE', 'rv', 'Pick', 'NS AM', 'STAK', 'FORKL', 'Tract', 'freig', \n",
    "         'Dumps', 'forkl', 'TRK', 'BROOM', 'Trail', 'Glass Rack', 'US POSTAL', 'TRT', 'pas', 'COM',  'CHERR', 'UTV', 'NEW Y', \n",
    "         'TOW T', 'tract', 'STREE' ]\n",
    "\n",
    "bus = ['Bus', 'School Bus', 'bus', 'MTA BUS', 'postal bus', 'MTA b', 'MTA B', 'SCHOO', 'schoo']\n",
    "\n",
    "taxi = ['Taxi', 'LIMO', 'Pedicab', 'Cab', 'TAXI', 'taxi cab', 'ride service']\n",
    "\n",
    "two_wheeled = ['E-Scooter', 'Motorbike', 'Motorcycle', 'Bike', 'E-Bike', 'Motorscooter', 'Minibike', 'Scooter', 'E-BIKE', 'scooter', \n",
    "                'E-UNICYCLE', 'SKATEBOARD', 'Minicycle', 'moped', 'SCOOTER', 'scoot', 'Scoot', 'e sco', 'E-Bik', 'EBIKE', 'motor', 'E-MOT', \n",
    "                'ELEC. UNIC', 'MOTORSCOOT', 'two', 'BICYC', 'ELECTRIC S', 'e-bik', 'bike', 'moto', 'GATOR', 'Motorcycle', 'MOPED', 'WHEEL',\n",
    "                'E-BIK', 'Wheel', 'SCOOT', 'Moped']\n",
    "\n",
    "others = ['Golf Cart', 'GOLF CART', 'forlift', 'Carry All', 'Street Swe', 'DELIVERY', 'UNKNOWN', 'Multi-Wheeled Vehicle', 'Fork Lift', 'FORKLIFT',\n",
    "          'Lawnmower', 'dark color', 'PC', 'Unknown', 'FD LADDER', 'OTH', 'Horse', 'JOHN DEERE', 'TOWER', 'Lunch Wagon', 'WORKH', \n",
    "          'WORK', '99999', 'const', 'BLOCK', 'unk', 'CRANE', 'BULLD', 'BK', 'seagr', 'Trc', 'Go kart', 'UNKN', 'Forklift', 'forklift', \n",
    "          'backhoe', 'gator','CONST', 'self', 'DEMA-', 'FORK-', '1C', 'Comm', 'SELF', 'fork', 'FORK', 'POWER', 'Sprin', 'FRONT', 'unknown', \n",
    "          'MOTOR', 'UNKNO', 'GRAY', np.nan]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['VEHICLE TYPE'] = df['VEHICLE TYPE'].replace(services, 'SERVICES')\n",
    "df['VEHICLE TYPE'] = df['VEHICLE TYPE'].replace(van, 'VAN')\n",
    "df['VEHICLE TYPE'] = df['VEHICLE TYPE'].replace(car, 'CAR')\n",
    "df['VEHICLE TYPE'] = df['VEHICLE TYPE'].replace(truck, 'TRUCK')\n",
    "df['VEHICLE TYPE'] = df['VEHICLE TYPE'].replace(bus, 'BUS')\n",
    "df['VEHICLE TYPE'] = df['VEHICLE TYPE'].replace(taxi, 'TAXI')\n",
    "df['VEHICLE TYPE'] = df['VEHICLE TYPE'].replace(two_wheeled, 'TWO_WHEELED')\n",
    "df['VEHICLE TYPE'] = df['VEHICLE TYPE'].replace(others, 'OTHERS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VEHICLE TYPE\n",
      "CAR            65200\n",
      "TRUCK           5953\n",
      "TAXI            3822\n",
      "TWO_WHEELED     1939\n",
      "BUS             1099\n",
      "VAN              562\n",
      "OTHERS           530\n",
      "SERVICES         278\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['VEHICLE TYPE'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRASH DATE                       0.000000\n",
       "CRASH TIME                       0.000000\n",
       "BOROUGH                          0.355252\n",
       "ZIP CODE                         0.355404\n",
       "LATITUDE                         0.060517\n",
       "LONGITUDE                        0.060517\n",
       "NUMBER OF PEDESTRIANS INJURED    0.000000\n",
       "NUMBER OF PEDESTRIANS KILLED     0.000000\n",
       "NUMBER OF CYCLIST INJURED        0.000000\n",
       "NUMBER OF CYCLIST KILLED         0.000000\n",
       "NUMBER OF MOTORIST INJURED       0.000000\n",
       "NUMBER OF MOTORIST KILLED        0.000000\n",
       "CONTRIBUTING FACTOR              0.002318\n",
       "VEHICLE TYPE                     0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing values percentages for each column\n",
    "df.isna().sum() / df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, since there are a large amount of missing Borough and Zip Code cells (over 28.200), we will infer their value using longitude and latitude coordinates for those rows with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LATITUDE'] = pd.to_numeric(df['LATITUDE'], errors='coerce')\n",
    "df['LONGITUDE'] = pd.to_numeric(df['LONGITUDE'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pandas geopandas shapely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ZIP CODE'] = pd.to_numeric(df['ZIP CODE'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.wkt import loads\n",
    "from shapely.geometry import Point\n",
    "\n",
    "zipcodes_df = pd.read_csv('data/zip_code_area.csv')\n",
    "boroughs_df = pd.read_csv('data/borough_area.csv')\n",
    "\n",
    "zipcodes_df['geometry'] = zipcodes_df['the_geom'].apply(loads)\n",
    "boroughs_df['geometry'] = boroughs_df['the_geom'].apply(loads)\n",
    "\n",
    "# convert dataframes to GeoDataFrames\n",
    "zipcodes_gdf = gpd.GeoDataFrame(zipcodes_df, geometry='geometry', crs=\"EPSG:4326\")\n",
    "boroughs_gdf = gpd.GeoDataFrame(boroughs_df, geometry='geometry', crs=\"EPSG:4326\")\n",
    "\n",
    "# Function to asses borough and zip code using latitude and longitude as input parameters\n",
    "def get_borough_zip(lat, lon):\n",
    "    point = Point(lon, lat)\n",
    "    \n",
    "    # Find borough\n",
    "    borough = None\n",
    "    for _, row in boroughs_gdf.iterrows():\n",
    "        if row['geometry'].contains(point):\n",
    "            borough = row['BoroName']\n",
    "            break\n",
    "    \n",
    "    # Find ZIP code\n",
    "    zip_code = None\n",
    "    for _, row in zipcodes_gdf.iterrows():\n",
    "        if row['geometry'].contains(point):\n",
    "            zip_code = row['MODZCTA']\n",
    "            break\n",
    "\n",
    "    return borough, zip_code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply get_borough_zip function to rows with missing BOROUGH or ZIP CODE values\n",
    "def complete_locations(data):\n",
    "    missing = data[data['BOROUGH'].isna() | data['ZIP CODE'].isna()]\n",
    "\n",
    "    for idx, row in missing.iterrows():\n",
    "        borough, zip_code = get_borough_zip(row['LATITUDE'], row['LONGITUDE'])\n",
    "        if borough:\n",
    "            data.at[idx, 'BOROUGH'] = borough\n",
    "        if zip_code:\n",
    "            data.at[idx, 'ZIP CODE'] = zip_code\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = complete_locations(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, for remaining rows with no Borough, Zip code, latitude nor longitude, plus the ones to have null latitude or longitude, we are going to discard them as their inclusion would interfere with data visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['LATITUDE', 'LONGITUDE', 'BOROUGH', 'ZIP CODE'])\n",
    "df = df[(df['LATITUDE'] != 0) & (df['LONGITUDE'] != 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all borough names are set to upper case letters\n",
    "df['BOROUGH'] = df['BOROUGH'].str.upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following this, we categorize matching contributing factors using clustering techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTRIBUTING FACTOR\n",
      "Driver Inattention/Distraction                           18493\n",
      "Unspecified                                              16233\n",
      "Following Too Closely                                     6774\n",
      "Failure to Yield Right-of-Way                             5102\n",
      "Backing Unsafely                                          3847\n",
      "Passing or Lane Usage Improper                            3329\n",
      "Passing Too Closely                                       3200\n",
      "Unsafe Lane Changing                                      2505\n",
      "Other Vehicular                                           2071\n",
      "Turning Improperly                                        1838\n",
      "Traffic Control Disregarded                               1320\n",
      "Driver Inexperience                                       1223\n",
      "Reaction to Uninvolved Vehicle                            1221\n",
      "Unsafe Speed                                              1045\n",
      "Alcohol Involvement                                        713\n",
      "View Obstructed/Limited                                    615\n",
      "Pedestrian/Bicyclist/Other Pedestrian Error/Confusion      522\n",
      "Oversized Vehicle                                          486\n",
      "Aggressive Driving/Road Rage                               336\n",
      "Pavement Slippery                                          320\n",
      "Brakes Defective                                           277\n",
      "Passenger Distraction                                      255\n",
      "Fell Asleep                                                201\n",
      "Obstruction/Debris                                         173\n",
      "Outside Car Distraction                                    160\n",
      "Pavement Defective                                         115\n",
      "Tire Failure/Inadequate                                    108\n",
      "Glare                                                      102\n",
      "Failure to Keep Right                                       99\n",
      "Steering Failure                                            96\n",
      "Fatigued/Drowsy                                             77\n",
      "Driverless/Runaway Vehicle                                  68\n",
      "Illnes                                                      57\n",
      "Lost Consciousness                                          54\n",
      "Drugs (illegal)                                             49\n",
      "Animals Action                                              46\n",
      "Accelerator Defective                                       42\n",
      "Lane Marking Improper/Inadequate                            38\n",
      "Cell Phone (hand-Held)                                      35\n",
      "Traffic Control Device Improper/Non-Working                 20\n",
      "Physical Disability                                         16\n",
      "Other Electronic Device                                     11\n",
      "Other Lighting Defects                                      10\n",
      "Vehicle Vandalism                                            8\n",
      "Eating or Drinking                                           7\n",
      "Tinted Windows                                               5\n",
      "Tow Hitch Defective                                          5\n",
      "Shoulders Defective/Improper                                 5\n",
      "Prescription Medication                                      5\n",
      "Using On Board Navigation Device                             3\n",
      "Cell Phone (hands-free)                                      3\n",
      "Windshield Inadequate                                        3\n",
      "Texting                                                      2\n",
      "Listening/Using Headphones                                   1\n",
      "Headlights Defective                                         1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['CONTRIBUTING FACTOR'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Distraction = ['Driver Inattention/Distraction', 'Cell Phone (hand-Held)', 'Passenger Distraction', 'Outside Car Distraction', \n",
    "               'Eating or Drinking', 'Using On Board Navigation Device', 'Cell Phone (hands-free)', 'Other Electronic Device', \n",
    "               'Texting','Listening/Using Headphones']\n",
    "\n",
    "Environment = ['Pavement Slippery', 'Pavement Defective', 'Obstruction/Debris', 'Animals Action', 'Pedestrian/Bicyclist/Other Pedestrian Error/Confusion', 'Lane Marking Improper/Inadequate']\n",
    "\n",
    "Motor_problem = ['Oversized Vehicle', 'Brakes Defective', 'Steering Failure', 'Tire Failure/Inadequate', 'Accelerator Defective', \n",
    "                 'Traffic Control Device Improper/Non-Working', 'Tinted Windows', 'Headlights Defective', 'Other Lighting Defects', \n",
    "                 'Shoulders Defective/Improper', 'Tow Hitch Defective', 'Windshield Inadequate']\n",
    "\n",
    "Driving_mistake = ['Unsafe Lane Changing', 'Failure to Yield Right-of-Way', 'Turning Improperly', 'Traffic Control Disregarded', \n",
    "                   'Unsafe Speed', 'Passing or Lane Usage Improper', 'Following Too Closely', 'Aggressive Driving/Road Rage', \n",
    "                   'Passing Too Closely', 'Backing Unsafely', 'Failure to Keep Right' ]\n",
    "\n",
    "Driver_related = ['Driver Inexperience', 'Fell Asleep', 'Illnes', 'Fatigued/Drowsy', \n",
    "                  'Lost Consciousness', 'Physical Disability', 'Prescription Medication']\n",
    "\n",
    "Driver_related_illegal = ['Alcohol Involvement', 'Drugs (illegal)']\n",
    "\n",
    "Other_vehicular = ['Other Vehicular', 'View Obstructed/Limited', 'Reaction to Uninvolved Vehicle', 'Glare']\n",
    "\n",
    "Uncontrolled = ['Driverless/Runaway Vehicle', 'Vehicle Vandalism']\n",
    "\n",
    "Unspecified = ['Unspecified', None, np.nan]\n",
    "\n",
    "\n",
    "df['CONTRIBUTING FACTOR'] = df['CONTRIBUTING FACTOR'].replace(Distraction, 'Driver distraction')\n",
    "df['CONTRIBUTING FACTOR'] = df['CONTRIBUTING FACTOR'].replace(Environment, 'Roadway issues')\n",
    "df['CONTRIBUTING FACTOR'] = df['CONTRIBUTING FACTOR'].replace(Motor_problem, 'Vehicle defect')\n",
    "df['CONTRIBUTING FACTOR'] = df['CONTRIBUTING FACTOR'].replace(Driving_mistake, 'Improper driving and traffic rules violation')\n",
    "df['CONTRIBUTING FACTOR'] = df['CONTRIBUTING FACTOR'].replace(Driver_related, 'Driver condition')\n",
    "df['CONTRIBUTING FACTOR'] = df['CONTRIBUTING FACTOR'].replace(Driver_related_illegal, 'Substance use')\n",
    "df['CONTRIBUTING FACTOR'] = df['CONTRIBUTING FACTOR'].replace(Other_vehicular, 'Vehicle interaction factors')\n",
    "df['CONTRIBUTING FACTOR'] = df['CONTRIBUTING FACTOR'].replace(Uncontrolled, 'Uncontrolled vehicle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTRIBUTING FACTOR\n",
      "Improper driving and traffic rules violation    29395\n",
      "Driver distraction                              18970\n",
      "Unspecified                                     16233\n",
      "Vehicle interaction factors                      4009\n",
      "Driver condition                                 1633\n",
      "Roadway issues                                   1214\n",
      "Vehicle defect                                   1058\n",
      "Substance use                                     762\n",
      "Uncontrolled vehicle                               76\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['CONTRIBUTING FACTOR'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, additional columns will be added regarding accidents' date and time to ease the following creation of visualizations. 4 new columns are created: Datetime (with the complete date), Month (with the month as a string), Hour (for the accidents' time), Week_day (with the day of the week as a string) and Day (for the day of the month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CRASH TIME'] = df['CRASH TIME'].apply(lambda x: x if len(x.split(':')) == 3 else x + ':00')\n",
    "\n",
    "df['DATETIME'] = pd.to_datetime(df['CRASH DATE'] + ' ' + df['CRASH TIME'], format='%m/%d/%Y %H:%M:%S')\n",
    "\n",
    "df['MONTH'] = df['DATETIME'].dt.strftime('%B')\n",
    "\n",
    "df['HOUR'] = df['DATETIME'].dt.hour\n",
    "\n",
    "df['WEEK_DAY'] = df['DATETIME'].dt.strftime('%A')\n",
    "\n",
    "df['DAY'] = df['DATETIME'].dt.day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, dataset with weather conditions will be merged to enrich current dataset with a column for the weather condition for adding context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather = pd.read_csv('data/weather2018.csv')\n",
    "\n",
    "df['CRASH DATE'] = pd.to_datetime(df['CRASH DATE'], format='%m/%d/%Y')\n",
    "df_weather['datetime'] = pd.to_datetime(df_weather['datetime'], format='%Y-%m-%d')\n",
    "\n",
    "df_weather.rename(columns={'datetime': 'CRASH DATE'}, inplace=True)\n",
    "\n",
    "df_crash = pd.merge(df, df_weather[['CRASH DATE', 'icon']], on='CRASH DATE', how='left')\n",
    "\n",
    "df_crash.rename(columns={'icon': 'WEATHER'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns regarding casualties will be added, plus a new column stating incidents' severity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total count of injuries and deaths\n",
    "df_crash['TOTAL_INJURIES'] = df_crash[['NUMBER OF PEDESTRIANS INJURED', \n",
    "                           'NUMBER OF CYCLIST INJURED', \n",
    "                           'NUMBER OF MOTORIST INJURED']].sum(axis=1)\n",
    "\n",
    "df_crash['TOTAL_DEATHS'] = df_crash[['NUMBER OF PEDESTRIANS KILLED', \n",
    "                         'NUMBER OF CYCLIST KILLED', \n",
    "                         'NUMBER OF MOTORIST KILLED']].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crash['SEVERITY'] = df_crash.apply(\n",
    "    lambda row: 'Death' if row['TOTAL_DEATHS'] > 0\n",
    "    else ('Injury' if row['TOTAL_INJURIES'] > 0 else 'No Damage'),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, some additional columns which have been useful to complete data but are no longer of use will be disregarded to have the simplest dataset possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crash.drop(columns=['CRASH DATE', 'CRASH TIME', \n",
    "                       'NUMBER OF PEDESTRIANS INJURED', 'NUMBER OF PEDESTRIANS KILLED',\n",
    "                       'NUMBER OF CYCLIST INJURED', 'NUMBER OF CYCLIST KILLED',\n",
    "                       'NUMBER OF MOTORIST INJURED', 'NUMBER OF MOTORIST KILLED'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['BOROUGH', 'ZIP CODE', 'LATITUDE', 'LONGITUDE', 'CONTRIBUTING FACTOR',\n",
       "       'VEHICLE TYPE', 'DATETIME', 'MONTH', 'HOUR', 'WEEK_DAY', 'DAY',\n",
       "       'WEATHER', 'TOTAL_INJURIES', 'TOTAL_DEATHS', 'SEVERITY'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_crash.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, resulting csv is stored as a csv file in the data folder to be used for further analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crash.to_csv('data/accidents_preprocessed.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
